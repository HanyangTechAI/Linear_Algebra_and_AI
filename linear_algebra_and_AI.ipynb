{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3Htdbg4QYO+Gc9ZWdqOXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaehoon1/Linear_Algebra_and_AI/blob/main/linear_algebra_and_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4zcFoVp8cKap"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mI63fVkuTXQn"
      },
      "outputs": [],
      "source": [
        "def build_vocab(text: str) -> list[str]:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    tokens = text.split()\n",
        "    vocab = sorted(list(set(tokens)))\n",
        "\n",
        "    return vocab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V 생성 함수"
      ],
      "metadata": {
        "id": "lq-gAb6bcQnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_corpus(text: str, vocab: list[str]) -> list[list[int]]:\n",
        "    word_to_id = {word: idx for idx, word in enumerate(vocab)}\n",
        "    sentences = text.lower().split('.')\n",
        "\n",
        "    corpus = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        clean = re.sub(r'[^a-z\\s]', ' ', sentence)\n",
        "        tokens = clean.split()\n",
        "\n",
        "        if not tokens:\n",
        "            continue\n",
        "\n",
        "        token_ids = [word_to_id[token] for token in tokens if token in word_to_id]\n",
        "\n",
        "        if token_ids:\n",
        "            corpus.append(token_ids)\n",
        "\n",
        "    return corpus\n"
      ],
      "metadata": {
        "id": "6fd8Ig24b0YI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "corpus 생성 함수"
      ],
      "metadata": {
        "id": "G_9QGJoQchbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/sample_data/multiverse.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "vocab = build_vocab(text)\n",
        "corpus = build_corpus(text, vocab)"
      ],
      "metadata": {
        "id": "y9-bs-oUcj9W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트 데이터로부터 V와 corpus 생성"
      ],
      "metadata": {
        "id": "d0byZEv4dvko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_D(corpus, window_size):\n",
        "    D = []\n",
        "    for sentence in corpus:\n",
        "        L = len(sentence)\n",
        "        for i, w in enumerate(sentence):\n",
        "            start = max(0, i - window_size)\n",
        "            end = min(L, i + window_size + 1)\n",
        "            for j in range(start, end):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                D.append((w, sentence[j]))\n",
        "    return D\n"
      ],
      "metadata": {
        "id": "lcxAjumkd7Is"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D 생성 함수"
      ],
      "metadata": {
        "id": "raJPSjfpgHiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def p_wc(D, w, c):\n",
        "  D_size = len(D)\n",
        "  pair_count = Counter(D)\n",
        "  return pair_count[(w, c)] / D_size if D_size > 0 else 0.0\n",
        "\n",
        "def p_w(D, w):\n",
        "  D_size = len(D)\n",
        "  w_count = Counter([w for w, _ in D])\n",
        "  return w_count[w] / D_size if D_size > 0 else 0.0\n",
        "\n",
        "def p_c(D, c):\n",
        "  D_size = len(D)\n",
        "  c_count = Counter([c for _, c in D])\n",
        "  return c_count[c] / D_size if D_size > 0 else 0.0"
      ],
      "metadata": {
        "id": "1O1jMmHKgNNL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "확률 함수"
      ],
      "metadata": {
        "id": "6n5GVXSdh41F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D = build_D(corpus, 5)"
      ],
      "metadata": {
        "id": "OcypaBxPoaaW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D 생성"
      ],
      "metadata": {
        "id": "bSX8KTBtqVs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c_counts = Counter([c for _, c in D])\n",
        "\n",
        "c_pow = {c: count ** (3/4) for c, count in c_counts.items()}\n",
        "\n",
        "total = sum(c_pow.values())\n",
        "\n",
        "p_D = {c: value / total for c, value in c_pow.items()}"
      ],
      "metadata": {
        "id": "NGnFTHnWqXaL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "p_D(c) 확률 분포 정의"
      ],
      "metadata": {
        "id": "NdQW7nqLrYQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_SPPMI_matrix(v, D, k=10):\n",
        "    \"\"\"\n",
        "    v: list[str] (vocab)\n",
        "    D: list[(w_idx, c_idx)]  (co-occurrence pairs)\n",
        "    k: negative sampling count (default 10)\n",
        "    return: numpy ndarray shape (|V|, |V|)\n",
        "    \"\"\"\n",
        "    V = len(v)\n",
        "    SPPMI = np.zeros((V, V), dtype=np.float32)\n",
        "\n",
        "    for w in range(V):\n",
        "        for c in range(V):\n",
        "            pwc = p_wc(D, w, c)\n",
        "            if pwc == 0:\n",
        "                continue\n",
        "\n",
        "            pw = p_w(D, w)\n",
        "            pc = p_c(D, c)\n",
        "\n",
        "            # PMI\n",
        "            pmi = math.log((pwc / (pw * pc)) + 1e-12)\n",
        "\n",
        "            # SPMI\n",
        "            spmi = pmi - math.log(k)\n",
        "\n",
        "            # SPPMI\n",
        "            if spmi > 0:\n",
        "                SPPMI[w, c] = spmi\n",
        "\n",
        "    return SPPMI"
      ],
      "metadata": {
        "id": "MrvG91hvrbO0"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}